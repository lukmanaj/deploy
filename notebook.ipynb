{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying My Small Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path, device):\n",
    "    \"\"\"\n",
    "    Loads a model from the specified file path.\n",
    "\n",
    "    Args:\n",
    "    model_path (str): Path to the model file.\n",
    "    device (str): The device to load the model on ('cuda' or 'cpu').\n",
    "\n",
    "    Returns:\n",
    "    torch.nn.Module: Loaded PyTorch model.\n",
    "    \"\"\"\n",
    "    weights = torchvision.models.DenseNet201_Weights.DEFAULT # best available weight\n",
    "    # Recreate the classifier layer and seed it to the target device\n",
    "    model = torchvision.models.densenet201(weights=weights).to(device)\n",
    "    model.classifier = torch.nn.Sequential(\n",
    "    torch.nn.Dropout(p=0.2, inplace=True),\n",
    "    torch.nn.Linear(in_features=1920,\n",
    "                    out_features=4, # same number of output units as our number of classes\n",
    "                    bias=True)).to(device)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    \"\"\"\n",
    "    Preprocesses the image for model prediction.\n",
    "\n",
    "    Args:\n",
    "    image_path (str): Path to the image file.\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor: Preprocessed image tensor.\n",
    "    \"\"\"\n",
    "    image = torchvision.io.read_image(image_path).type(torch.float32)\n",
    "    image = image / 255.0  # Normalize to [0, 1]\n",
    "    transform = transforms.Resize(size=(64, 64))\n",
    "    return transform(image)\n",
    "\n",
    "def get_prediction(model, image, device):\n",
    "    \"\"\"\n",
    "    Predicts the class for the given image using the specified model.\n",
    "\n",
    "    Args:\n",
    "    model (torch.nn.Module): The trained model for prediction.\n",
    "    image (torch.Tensor): The preprocessed image tensor.\n",
    "    device (str): The device to perform prediction on ('cuda' or 'cpu').\n",
    "\n",
    "    Returns:\n",
    "    str, float: Predicted class name and the probability.\n",
    "    \"\"\"\n",
    "    class_names = ['buffalo', 'elephant', 'rhino', 'zebra']\n",
    "    image = image.unsqueeze(0).to(device)  # Add batch dimension and move to device\n",
    "    with torch.inference_mode():\n",
    "        pred_logits = model(image)\n",
    "        pred_prob = torch.softmax(pred_logits, dim=1)\n",
    "        pred_label = torch.argmax(pred_prob, dim=1)\n",
    "    return class_names[pred_label], pred_prob.max().item()\n",
    "\n",
    "def predict_image(image_path, model_path):\n",
    "    \"\"\"\n",
    "    Main function to handle model prediction on the given image.\n",
    "\n",
    "    Args:\n",
    "    image_path (str): Path to the target image.\n",
    "    model_path (str): Path to the trained model file.\n",
    "    \"\"\"\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"[INFO] Predicting on image: {image_path}\")\n",
    "\n",
    "    # Load the model and preprocess the image\n",
    "    model = load_model(model_path, device)\n",
    "    image = preprocess_image(image_path)\n",
    "\n",
    "    # Predict and print the result\n",
    "    pred_class, pred_prob = get_prediction(model, image, device)\n",
    "    print(f\"[INFO] Predicted class: {pred_class}, Probability: {pred_prob:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'image/buffalo.jpeg'\n",
    "model_path = 'model/densenetafri.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Predicting on image: image/buffalo.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/densenet201-c1103571.pth\" to /home/lukmanaj/.cache/torch/hub/checkpoints/densenet201-c1103571.pth\n",
      "100%|██████████| 77.4M/77.4M [00:08<00:00, 9.45MB/s]\n",
      "/home/lukmanaj/miniconda3/envs/arewads/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Predicted class: buffalo, Probability: 0.963\n"
     ]
    }
   ],
   "source": [
    "predict_image(image_path,model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works. I'm done. We move."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arewads",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
